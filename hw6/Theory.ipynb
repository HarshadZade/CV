{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7d652a58cfa010e75d4fa9c7414edd77",
     "grade": false,
     "grade_id": "cell-b2250668e6fbbab8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<img align=\"center\" src=\"img/course.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16720 (B)  Object Tracking in Videos - Assignment 6\n",
    "    Instructor: Kris                             TAs: Arka, Rohan, Rawal, Sheng-Yu, Jinkun\n",
    "\n",
    "# Instructions\n",
    "\n",
    "This section should include the visualizations and answers to specifically highlighted questions from Q1 to Q3. This section will need to be uploaded to gradescope as a pdf and manually graded (this is a separate submission from the coding notebooks) \n",
    "\n",
    "\n",
    "1. Students are encouraged to work in groups but each student must submit their own work. Include the names of your collaborators in your write up. Code should <span style='color:red'>Not</span>  be shared or copied. Please properly give credits to others by <span style='color:red'>LISTING EVERY COLLABORATOR</span> in the writeup including any code segments that you discussed,  Please <span style='color:red'>DO NOT</span>  use external code unless permitted. Plagiarism is prohibited and may lead to failure of this course.\n",
    "\n",
    "2.  **Start early!** This homework will take a long time to complete.\n",
    "    \n",
    "3. **Questions:** If you have any question, please look at Piazza first and the FAQ page for this homework.\n",
    "\n",
    "4. All the theory question and manually graded questions should be included in a single writeup (this notebook exported as pdf or a standalone pdf file) and submitted to gradescope: pdf assignment. \n",
    "\n",
    "5. **Attempt to verify your implementation as you proceed:** If you donâ€™t verify that your implementation is correct on toy examples, you will risk having a huge issue when you put everything together. We provide some simple checks in the notebook cells, but make sure you verify them on more complicated samples before moving forward. \n",
    "\n",
    "6. **Do not import external functions/packages other than the ones already imported in the files:** The current imported functions and packages are enough for you to complete this assignment. If you need to import other functions, please remember to comment them out after submission. Our autograder will crash if you import a new function that the gradescope server does not expect. \n",
    "\n",
    "7. Assignments that do not follow this submission rule will be **penalized up to 10\\% of the total score**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2cbb4a8045c681d69dd2876c6132b780",
     "grade": false,
     "grade_id": "cell-nkj283y4kjfdedsz",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Preliminaries\n",
    "In this section, we will go through some of the basics of the Lucas-Kanade tracker and the Matthews-Baker tracker. The following table contains a summary of the variables used in the rest of the assignment.\n",
    "\n",
    "![title](img/variables.PNG)\n",
    "\n",
    "## Template\n",
    "A template describes the object of interest (eg. a car, football) which we wish to track in a video. Traditionally, the tracking algorithm is initialized with a template, which is represented by a bounding box around the object to be tracked in the first frame of the video. For each of the subsequent frames in the video, the tracker will update its estimate of the object in the image. The tracker achieves this by updating its affine warp.\n",
    "\n",
    "## Warps\n",
    "What is a warp? An image transformation or warp $\\textbf{W}$ is a function that acts on pixel coordinates $\\textbf{x} = \\left[u\\;\\;v\\right]^T$\n",
    "and maps pixel values from one place to another in an image $\\textbf{x}' =\n",
    "\\left[u'\\;\\;v'\\right]^T$. Simply put, $\\textbf{W}$ maps a pixel with coordinates $\\textbf{x} = \\left[u\\;\\;v\\right]^T$ to $\\textbf{x}' =\n",
    "\\left[u'\\;\\;v'\\right]^T$. Translation, rotation, and scaling are all examples of warps. We denote the parameters of the warp function $\\textbf{W}$ by $\\textbf{p}$: \n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\textbf{x}'= \\textbf{W}(\\textbf{x};\\textbf{p})\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "## Affine Warp\n",
    "An affine warp is a particular kind of warp that can include any combination of translation, scaling, and rotations. An affine warp can be represented by 6 parameters $\\textbf{p} = [p_1\\;p_2\\;p_3\\;p_4\\;p_5\\;p_6]^{T}$. One of the most convenient things about an affine warp is that it is linear; its action on a point with coordinates $\\textbf{x} = \\left[u\\;\\;v\\right]^T$ can be described as a matrix operation by a $3 \\times 3$ matrix $\\textbf{W}(\\textbf{p})$:,\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\left[ \\begin{array}{c} u' \\\\ v' \\\\ 1 \\end{array} \\right] = \\textbf{W}(\\textbf{p}) \\left[\n",
    "\\begin{array}{c} u \\\\ v \\\\ 1 \\end{array} \\right]\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\textbf{W}(\\textbf{p}) = \\begin{bmatrix} 1+p_1 & p_3 & p_5 \\\\ p_2 & 1+p_4 & p_6 \\\\ 0 & 0 & 1 \\end{bmatrix}\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "Note: For convenience, when we want to refer to the warp as a function, we will use $\\textbf{W}(\\textbf{x};\\textbf{p})$ and when we want to refer to the matrix for an affine warp, we will use $\\textbf{W}(\\textbf{p})$. We will use affine warp and affine transformation interchangeably."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9433820d0a93d83fb734962f39766cc",
     "grade": false,
     "grade_id": "cell-1b45fd1c3c38945a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Theory Questions (30 pts)\n",
    "\n",
    "Before implementing the trackers, let's study some simple problems that will be useful during the implementation first. The answers to the below questions should be relatively short, consisting of a few lines of math and text.  \n",
    "\n",
    "## Q1.1\n",
    "Assuming the affine warp model defined above, derive the expression for the $\\frac{\\partial \\textbf{W}}{\\partial \\textbf{p}}$ in terms of the warp parameters $\\textbf{p} = [p_1\\;p_2\\;p_3\\;p_4\\;p_5\\;p_6]'$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51769ea153121bc0007a4981af4d779d",
     "grade": true,
     "grade_id": "cell-ddb4d1f50ebcaec0",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE <br/>\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\textbf{W}(\\textbf{X,p}) = \\begin{bmatrix} 1+p_1 & p_3 & p_5 \\\\ p_2 & 1+p_4 & p_6 \\\\ 0 & 0 & 1 \\end{bmatrix} \\left[\\begin{array}{c} u \\\\ v \\\\ 1 \\end{array}\\right]\n",
    "\\end{gathered} \n",
    "$$\n",
    "\n",
    "\n",
    "$\\implies$\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\textbf{W}(\\textbf{X,p}) = \\begin{bmatrix} (1+p_1)u + p_3v + p_5 \\\\ p_2u + (1+p_4)v + p_6 \\\\ 1 \\end{bmatrix}\n",
    "\\end{gathered}\n",
    "$$\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial W}{\\partial p} = \\left[ \\begin{array}{c} \\frac{\\partial W_{1}}{\\partial p} \\\\ \\frac{\\partial W_{2}}{\\partial p} \\end{array} \\right] = \\left[ \\begin{array}{c} u & 0 & v & 0 & 1 & 0 \\\\ 0 & u & 0 & v & 0 & 1 \\end{array} \\right] \n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3308c64e096019ce7cf7b08581cb289",
     "grade": false,
     "grade_id": "cell-fc866101ec15f385",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q1.2\n",
    "Find the computational complexity (Big O notation) for each runtime iteration (computing $\\textbf{J}$ and $\\textbf{H}^{-1}$) of the Lucas Kanade method. Express your answers in terms of $n$, $m$ and $p$ where $n$ is the number of pixels in thetemplate $\\textbf{T}$, $m$ is the number of pixels in an input image $\\textbf{I}$ and $p$ is the number of parameters used to describe the warp $W$.\n",
    "\n",
    "You may refer to the supplementary PDF for more detailed descriptions of the algorithm."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba829252163d38ffaacb6c82f5e57269",
     "grade": true,
     "grade_id": "cell-d618bdb98a0d5f94",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE <br/>\n",
    "1. For image warping by an affine warp (on every pixel): $O(mp)$\n",
    "2. $O(np)$ for finding the error by taking the difference.\n",
    "3. For warping the gradient by an affine warp: $O(mp)$\n",
    "4. To evaluate the jacobian: $O(np)$ (n pixels and p parameters)\n",
    "5. For getting the steepest descent, we multiply $\\nabla I$ and $\\frac{\\partial W}{\\partial p}$. Therefore: $O(n p)$ \n",
    "6. Commputation of Hessian: $O\\left(n^2 p\\right)$\n",
    "7. For getting the difference that has to be updated, we multiply three matrices. Therefore, $O\\left(n^3\\right)$\n",
    "8. Final update step: $O(np)$\n",
    "\n",
    "Therefore overall complexity will be given by: $O\\left(n^3+n^2 p\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d6cb4dff6239e98d33174eb80bac1eb5",
     "grade": false,
     "grade_id": "cell-9d505035dba56563",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q1.3\n",
    "Find the computational complexity (Big O notation) for the initialization step (Precomputing $\\textbf{J}$ and $\\textbf{H}^{-1}$) and for each runtime iteration of the Matthews-Baker method. Express your answers in terms of $n$, $m$ and $p$ where $n$ is the number of pixels in the template $\\textbf{T}$, $m$ is the number of pixels in an input image $\\textbf{I}$ and $p$ is the number of parameters used to describe the warp $W$. You may refer to the supplementary PDF for more detailed descriptions of the algorithm.\n",
    "\n",
    "How does this compare to the run time of the regular Lucas-Kanade method?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae37223040cd1e09dd9da48ed35c9b32",
     "grade": true,
     "grade_id": "cell-95b51fa815c97b28",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE <br/>\n",
    "Before the loop: <br/>\n",
    "1. $=O(n)$ to calculate gradient of template image\n",
    "2. $O(n p)$ for Jcobian\n",
    "3. For getting the steepest descent: $O\\left(n^2 p\\right)$\n",
    "4. To calculate the Hessian matrix: $O\\left(n^2 p\\right)$\n",
    "\n",
    "Inside the loop: <br/>\n",
    "- For image warping by an affine warp (on every pixel): $O(mp)$\n",
    "- $O(np)$ for finding the error by taking the difference.\n",
    "- To multiply $J^T$ and E: $O(mp)$ \n",
    "- For getting $\\delta p$, we multiply three matrices. Therefore, $O\\left(n^3\\right)$\n",
    "- Final warp update is of the order $O\\left(p^2\\right)$\n",
    "\n",
    "So before the loop: $O\\left(n^2 p\\right)$ and in loop computation is of the order: $O\\left(m p+p^3\\right)$\n",
    "\n",
    "If we compare this to the previous one (Lucas-Kanade), we can see that this is significantly smaller! (as p << n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2dbd3e8c0e92e6c62b8043d8bc4eec01",
     "grade": false,
     "grade_id": "cell-dbed38f544a88ed5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Coding Questions Write-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e4b14a6392699333126d98ae4770f0c",
     "grade": false,
     "grade_id": "cell-9d505035dba565as",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q1.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7059713fd50d874abbfb5d2b171af19",
     "grade": true,
     "grade_id": "cell-95b51fa815c97b21",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE <br/>\n",
    "Results for ballet.npy: <br/>\n",
    "![](Q1_1ballet1.png) <br />\n",
    "![](Q1_1ballet2.png) <br />\n",
    "![](Q1_1ballet3.png) <br />\n",
    "![](Q1_1ballet4.png) <br />\n",
    "![](Q1_1ballet5.png) <br />\n",
    "\n",
    "Results for car1.npy: <br/>\n",
    "![](Q1_1car1.png) <br />\n",
    "![](Q1_1car2.png) <br />\n",
    "![](Q1_1car3.png) <br />\n",
    "![](Q1_1car4.png) <br />\n",
    "![](Q1_1car5.png) <br />\n",
    "![](Q1_1car6.png) <br />\n",
    "![](Q1_1car7.png) <br />\n",
    "![](Q1_1car8.png) <br />\n",
    "![](Q1_1car9.png) <br />\n",
    "![](Q1_1car10.png) <br />\n",
    "![](Q1_1car11.png) <br />\n",
    "![](Q1_1car12.png) <br />\n",
    "![](Q1_1car13.png) <br />\n",
    "![](Q1_1car14.png) <br />\n",
    "![](Q1_1car15.png) <br />\n",
    "![](Q1_1car16.png) <br />\n",
    "\n",
    "Results for car2.npy <br/>\n",
    "![](Q1_1newcar1.png) <br />\n",
    "![](Q1_1newcar2.png) <br />\n",
    "![](Q1_1newcar3.png) <br />\n",
    "![](Q1_1newcar4.png) <br />\n",
    "![](Q1_1newcar5.png) <br />\n",
    "![](Q1_1newcar6.png) <br />\n",
    "![](Q1_1newcar7.png) <br />\n",
    "![](Q1_1newcar8.png) <br />\n",
    "![](Q1_1newcar9.png) <br />\n",
    "![](Q1_1newcar10.png) <br />\n",
    "![](Q1_1newcar11.png) <br />\n",
    "![](Q1_1newcar12.png) <br />\n",
    "![](Q1_1newcar13.png) <br />\n",
    "![](Q1_1newcar14.png) <br />\n",
    "![](Q1_1newcar15.png) <br />\n",
    "![](Q1_1newcar16.png) <br />\n",
    "![](Q1_1newcar17.png) <br />\n",
    "\n",
    "Results for landing.npy <br/>\n",
    "![](Q1_1landing1.png) <br />\n",
    "![](Q1_1landing2.png) <br />\n",
    "![](Q1_1landing3.png) <br />\n",
    "![](Q1_1landing4.png) <br />\n",
    "![](Q1_1landing5.png) <br />\n",
    "![](Q1_1landing6.png) <br />\n",
    "\n",
    "Results for race.npy <br/>\n",
    "![](Q1_1race1.png) <br />\n",
    "![](Q1_1race2.png) <br />\n",
    "![](Q1_1race3.png) <br />\n",
    "![](Q1_1race4.png) <br />\n",
    "![](Q1_1race5.png) <br />\n",
    "![](Q1_1race6.png) <br />\n",
    "![](Q1_1race7.png) <br />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LucasKanade(It, It1, rect, thresh=.025, maxIt=100):\n",
    "    \n",
    "    '''\n",
    "    Q1.1: Lucas-Kanade Forward Additive Alignment with Translation Only\n",
    "    \n",
    "      Inputs: \n",
    "        It: template image\n",
    "        It1: Current image\n",
    "        rect: Current position of the object\n",
    "        (top left, bottom right coordinates, x1, y1, x2, y2)\n",
    "        thresh: Stop condition when dp is too small\n",
    "        maxIt: Maximum number of iterations to run\n",
    "        \n",
    "      Outputs:\n",
    "        p: movement vector dx, dy\n",
    "    '''\n",
    "    # print(It.shape)\n",
    "    # print(It1.shape)\n",
    "    # Set thresholds (you probably want to play around with the values)\n",
    "    p = np.zeros(2) # dx, dy\n",
    "    threshold = thresh\n",
    "    maxIters = maxIt\n",
    "    i = 0\n",
    "    x1, y1, x2, y2 = rect\n",
    "    \n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    # del_Px, del_Py = 1, 1\n",
    "    del_p = np.ones(2,)\n",
    "    img_t_spline = RectBivariateSpline(np.arange(It.shape[0]), np.arange(It.shape[1]), It)\n",
    "    mesh_x, mesh_y = np.meshgrid(np.arange(x1,x2), np.arange(y1,y2))\n",
    "    wrapped_img_t_spline = (img_t_spline.ev(mesh_y ,mesh_x)).flatten()\n",
    "\n",
    "    img_t1_spline = RectBivariateSpline(np.arange(It1.shape[0]), np.arange(It1.shape[1]), It1)\n",
    "    grady_img_t1, gradx_img_t1 = np.gradient(It1)\n",
    "    gradx_img_t1_spline = RectBivariateSpline(np.arange(It1.shape[0]), np.arange(It1.shape[1]), gradx_img_t1)\n",
    "    grady_img_t1_spline = RectBivariateSpline(np.arange(It1.shape[0]), np.arange(It1.shape[1]), grady_img_t1)\n",
    "\n",
    "    curr_itr = 0\n",
    "    while np.linalg.norm(del_p) > threshold and curr_itr < maxIters:\n",
    "    # while curr_itr < maxIters:\n",
    "\n",
    "      del_Px = p[0]\n",
    "      del_Py = p[1]\n",
    "      mesh_x_temp = mesh_x + del_Px\n",
    "      mesh_y_temp = mesh_y + del_Py\n",
    "\n",
    "      wrapped_img_t1_spline = (img_t1_spline.ev(mesh_y_temp, mesh_x_temp)).flatten()\n",
    "      \n",
    "      b = wrapped_img_t_spline - wrapped_img_t1_spline\n",
    "\n",
    "      wrapped_gradx = gradx_img_t1_spline.ev(mesh_y_temp, mesh_x_temp).flatten()\n",
    "      wrapped_grady = grady_img_t1_spline.ev(mesh_y_temp, mesh_x_temp).flatten()\n",
    "\n",
    "      # A = np.column_stack((wrapped_gradx, wrapped_grady))\n",
    "      A = np.stack((wrapped_gradx, wrapped_grady), axis = 1)\n",
    "      # A = np.vstack((wrapped_gradx, wrapped_grady))\n",
    "      # A = A.reshape((2,1))\n",
    "\n",
    "      del_p = np.linalg.lstsq(A, b, rcond=-1)[0]\n",
    "      # del_p = del_p[0]\n",
    "      # print(del_p.shape)\n",
    "      # if np.linalg.norm(del_p) > threshold:\n",
    "      #   break\n",
    "      # else:\n",
    "      p += del_p\n",
    "      curr_itr += 1\n",
    "      \n",
    "      \n",
    "      \n",
    "\n",
    "\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd67a14946eb87c0f6c4f4e2640c0543",
     "grade": false,
     "grade_id": "cell-9d505035dba56567",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q1.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "397993e9437f23f9f670651e4af9ca2c",
     "grade": true,
     "grade_id": "cell-95b51fa815c97b30",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "Results for ballet.npy: <br/>\n",
    "![](Q1_2ballet1.png) <br />\n",
    "![](Q1_2ballet2.png) <br />\n",
    "![](Q1_2ballet3.png) <br />\n",
    "![](Q1_2ballet4.png) <br />\n",
    "![](Q1_2ballet5.png) <br />\n",
    "\n",
    "Results for car1.npy: <br/>\n",
    "![](Q1_2car1.png) <br />\n",
    "![](Q1_2car2.png) <br />\n",
    "![](Q1_2car3.png) <br />\n",
    "![](Q1_2car4.png) <br />\n",
    "![](Q1_2car5.png) <br />\n",
    "![](Q1_2car6.png) <br />\n",
    "![](Q1_2car7.png) <br />\n",
    "![](Q1_2car8.png) <br />\n",
    "![](Q1_2car9.png) <br />\n",
    "![](Q1_2car10.png) <br />\n",
    "![](Q1_2car11.png) <br />\n",
    "![](Q1_2car12.png) <br />\n",
    "![](Q1_2car13.png) <br />\n",
    "![](Q1_2car14.png) <br />\n",
    "![](Q1_2car15.png) <br />\n",
    "\n",
    "Results for car2.npy <br/>\n",
    "![](Q1_2newcar1.png) <br />\n",
    "![](Q1_2newcar2.png) <br />\n",
    "![](Q1_2newcar3.png) <br />\n",
    "![](Q1_2newcar4.png) <br />\n",
    "![](Q1_2newcar5.png) <br />\n",
    "![](Q1_2newcar6.png) <br />\n",
    "![](Q1_2newcar7.png) <br />\n",
    "![](Q1_2newcar8.png) <br />\n",
    "![](Q1_2newcar9.png) <br />\n",
    "![](Q1_2newcar10.png) <br />\n",
    "![](Q1_2newcar11.png) <br />\n",
    "![](Q1_2newcar12.png) <br />\n",
    "![](Q1_2newcar13.png) <br />\n",
    "\n",
    "Results for landing.npy <br/>\n",
    "![](Q1_2landing1.png) <br />\n",
    "![](Q1_2landing2.png) <br />\n",
    "![](Q1_2landing3.png) <br />\n",
    "![](Q1_2landing4.png) <br />\n",
    "![](Q1_2landing5.png) <br />\n",
    "![](Q1_2landing6.png) <br />\n",
    "\n",
    "Results for race.npy <br/>\n",
    "![](Q1_2race1.png) <br />\n",
    "![](Q1_2race2.png) <br />\n",
    "![](Q1_2race3.png) <br />\n",
    "![](Q1_2race4.png) <br />\n",
    "![](Q1_2race5.png) <br />\n",
    "![](Q1_2race6.png) <br />\n",
    "![](Q1_2race7.png) <br />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LucasKanadeAffine(It, It1, rect, thresh=.025, maxIt=100):\n",
    "    '''\n",
    "    Q1.2: Lucas-Kanade Forward Additive Alignment with Affine MAtrix\n",
    "    \n",
    "      Inputs: \n",
    "        It: template image\n",
    "        It1: Current image\n",
    "        rect: Current position of the object\n",
    "        (top left, bottom right coordinates, x1, y1, x2, y2)\n",
    "        thresh: Stop condition when dp is too small\n",
    "        maxIt: Maximum number of iterations to run\n",
    "        \n",
    "      Outputs:\n",
    "        M: Affine mtarix (2x3)\n",
    "    '''\n",
    "\n",
    "    # Set thresholds (you probably want to play around with the values)\n",
    "    M = np.zeros((2,3))\n",
    "    threshold = thresh\n",
    "    maxIters = maxIt\n",
    "    i = 0\n",
    "    x1, y1, x2, y2 = rect\n",
    "    \n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    p = np.zeros(6) # dx, dy\n",
    "    del_p = np.ones(6,)\n",
    "    img_t_spline = RectBivariateSpline(np.arange(It.shape[0]), np.arange(It.shape[1]), It)\n",
    "    mesh_x, mesh_y = np.meshgrid(np.arange(x1,x2), np.arange(y1,y2))\n",
    "    wrapped_img_t_spline = img_t_spline.ev(mesh_y ,mesh_x).flatten()\n",
    "    \n",
    "    img_t1_spline = RectBivariateSpline(np.arange(It1.shape[0]), np.arange(It1.shape[1]), It1)\n",
    "    grady_img_t1, gradx_img_t1 = np.gradient(It1)\n",
    "    gradx_img_t1_spline = RectBivariateSpline(np.arange(It1.shape[0]), np.arange(It1.shape[1]), gradx_img_t1)\n",
    "    grady_img_t1_spline = RectBivariateSpline(np.arange(It1.shape[0]), np.arange(It1.shape[1]), grady_img_t1)\n",
    "\n",
    "    homo_mesh = np.vstack((mesh_x.flatten(), mesh_y.flatten(), np.ones(mesh_x.shape[0]*mesh_x.shape[1])))\n",
    "    curr_itr = 0\n",
    "    while np.linalg.norm(del_p) > threshold and curr_itr < maxIters:\n",
    "      \n",
    "      W = np.array([[1,0,0],[0,1,0]])+np.array([[p[0], p[2], p[4]], [p[1], p[3], p[5]]])\n",
    "      homo = np.array([0,0,1])\n",
    "      W = np.vstack((W, homo))\n",
    "      warped_block = np.matmul(W, homo_mesh)\n",
    "      wrapped_img_t1_spline = img_t1_spline.ev(warped_block[1,:], warped_block[0,:])\n",
    "      \n",
    "      b = wrapped_img_t_spline - wrapped_img_t1_spline\n",
    "\n",
    "      wrapped_gradx = gradx_img_t1_spline.ev(warped_block[1,:], warped_block[0,:])\n",
    "      wrapped_grady = grady_img_t1_spline.ev(warped_block[1,:], warped_block[0,:])\n",
    "      wrapped_gradx = np.expand_dims(wrapped_gradx, axis=1)\n",
    "      wrapped_grady = np.expand_dims(wrapped_grady, axis=1)\n",
    "      # print(wrapped_gradx.shape)\n",
    "      grad = np.dstack((wrapped_gradx, wrapped_grady))\n",
    "      x_coords = np.expand_dims(warped_block[0,:], axis=1)\n",
    "      y_coords = np.expand_dims(warped_block[1,:], axis=1)\n",
    "      # print(y_coords.shape)\n",
    "      # print(\"zerp\",np.zeros((x_coords.shape)).shape)\n",
    "      dhoW_dhoP1 = np.dstack((x_coords, np.zeros((x_coords.shape)), y_coords, np.zeros((x_coords.shape)), np.ones((x_coords.shape)), np.zeros((x_coords.shape))))\n",
    "      dhoW_dhoP2 = np.dstack((np.zeros((x_coords.shape)), x_coords, np.zeros((x_coords.shape)), y_coords, np.zeros((x_coords.shape)), np.ones((x_coords.shape))))\n",
    "      # print(\"check\", dhoW_dhoP2.shape)\n",
    "      # dhoW_dhoP = np.stack((dhoW_dhoP1, dhoW_dhoP2), axis=1)\n",
    "      dhoW_dhoP = np.hstack((dhoW_dhoP1, dhoW_dhoP2))\n",
    "      # print(\"grad\",grad.shape)\n",
    "      # print(\"dhow\", dhoW_dhoP.shape)\n",
    "      # raise NotImplementedError()\n",
    "      A = np.matmul(grad, dhoW_dhoP)\n",
    "      A = A[:,0,:]\n",
    "      \n",
    "      del_p = np.linalg.lstsq(A, b, rcond=None)[0]\n",
    "      p += del_p\n",
    "      curr_itr += 1\n",
    "    M = np.array([[1 + p[0], p[2], p[4]], [p[1], 1+p[3], p[5]]])\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "084d6da395e21296b7ecfd66c5f4d61d",
     "grade": false,
     "grade_id": "cell-9d505035dba56568",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2.1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ba5ee7a9ef97ddacf0c74711b9846b5",
     "grade": true,
     "grade_id": "cell-95b51fa815c97b31",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "Results for ballet.npy: <br/>\n",
    "![](Q2ballet1.png) <br />\n",
    "![](Q2ballet2.png) <br />\n",
    "![](Q2ballet3.png) <br />\n",
    "![](Q2ballet4.png) <br />\n",
    "![](Q2ballet5.png) <br />\n",
    "![](Q2ballet6.png) <br />\n",
    "\n",
    "Results for car1.npy: <br/>\n",
    "![](Q2car1.png) <br />\n",
    "![](Q2car2.png) <br />\n",
    "![](Q2car3.png) <br />\n",
    "![](Q2car4.png) <br />\n",
    "![](Q2car5.png) <br />\n",
    "![](Q2car6.png) <br />\n",
    "![](Q2car7.png) <br />\n",
    "![](Q2car8.png) <br />\n",
    "![](Q2car9.png) <br />\n",
    "![](Q2car10.png) <br />\n",
    "![](Q2car11.png) <br />\n",
    "![](Q2car12.png) <br />\n",
    "\n",
    "Results for car2.npy <br/>\n",
    "![](Q2newcar1.png) <br />\n",
    "![](Q2newcar2.png) <br />\n",
    "![](Q2newcar3.png) <br />\n",
    "![](Q2newcar4.png) <br />\n",
    "![](Q2newcar5.png) <br />\n",
    "![](Q2newcar6.png) <br />\n",
    "![](Q2newcar7.png) <br />\n",
    "![](Q2newcar8.png) <br />\n",
    "![](Q2newcar9.png) <br />\n",
    "![](Q2newcar10.png) <br />\n",
    "![](Q2newcar11.png) <br />\n",
    "![](Q2newcar12.png) <br />\n",
    "![](Q2newcar13.png) <br />\n",
    "![](Q2newcar14.png) <br />\n",
    "![](Q2newcar15.png) <br />\n",
    "![](Q2newcar16.png) <br />\n",
    "![](Q2newcar17.png) <br />\n",
    "![](Q2newcar18.png) <br />\n",
    "![](Q2newcar19.png) <br />\n",
    "\n",
    "Results for landing.npy <br/>\n",
    "![](Q2landing1.png) <br />\n",
    "![](Q2landing2.png) <br />\n",
    "![](Q2landing3.png) <br />\n",
    "![](Q2landing4.png) <br />\n",
    "![](Q2landing5.png) <br />\n",
    "![](Q2landing6.png) <br />\n",
    "\n",
    "Results for race.npy <br/>\n",
    "![](Q2race1.png) <br />\n",
    "![](Q2race2.png) <br />\n",
    "![](Q2race3.png) <br />\n",
    "![](Q2race4.png) <br />\n",
    "![](Q2race5.png) <br />\n",
    "![](Q2race6.png) <br />\n",
    "![](Q2race7.png) <br />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InverseCompositionAffine(It, It1, rect, thresh=.025, maxIt=100):\n",
    "    '''\n",
    "    Q2.1: Matthew-Bakers Inverse Compositional Alignment with Affine MAtrix\n",
    "    \n",
    "      Inputs: \n",
    "        It: template image\n",
    "        It1: Current image\n",
    "        rect: Current position of the object\n",
    "        (top left, bottom right coordinates, x1, y1, x2, y2)\n",
    "        thresh: Stop condition when dp is too small\n",
    "        maxIt: Maximum number of iterations to run\n",
    "        \n",
    "      Outputs:\n",
    "        M: Affine mtarix (2x3)\n",
    "    '''\n",
    "    \n",
    "    # Set thresholds (you probably want to play around with the values)\n",
    "    M = np.zeros((2,3))\n",
    "    threshold = thresh\n",
    "    maxIters = maxIt\n",
    "    i = 0\n",
    "    x1, y1, x2, y2 = rect\n",
    "    \n",
    "    # ----- TODO -----\n",
    "    # YOUR CODE HERE\n",
    "    p = np.zeros(6,)\n",
    "    # del_p = np.ones(6,)\n",
    "    \n",
    "    img_t_spline = RectBivariateSpline(np.arange(It.shape[0]), np.arange(It.shape[1]), It)\n",
    "    mesh_x, mesh_y = np.meshgrid(np.linspace(x1, x2, int(x2-x1)+1), np.linspace(y1, y2, int(y2-y1)+1))\n",
    "    wrapped_img_t_spline = img_t_spline.ev(mesh_y ,mesh_x).flatten()\n",
    "\n",
    "    img_t1_spline = RectBivariateSpline(np.arange(It1.shape[0]), np.arange(It1.shape[1]), It1)\n",
    "    homo_mesh = np.vstack((mesh_x.flatten(), mesh_y.flatten(), np.ones(mesh_x.shape[0]*mesh_x.shape[1])))    \n",
    "    gradx_img_t1_spline = img_t_spline.ev(homo_mesh[1,:], homo_mesh[0,:], dy=1)\n",
    "    grady_img_t1_spline = img_t_spline.ev(homo_mesh[1,:], homo_mesh[0,:], dx=1)\n",
    "    \n",
    "    gradx_img_t1_spline = np.expand_dims(gradx_img_t1_spline, axis=1)\n",
    "    grady_img_t1_spline = np.expand_dims(grady_img_t1_spline, axis=1)\n",
    "    # print(\"gradx_img_t1\", gradx_img_t1_spline.shape)\n",
    "    grad = np.dstack((gradx_img_t1_spline, grady_img_t1_spline))\n",
    "    x_coords = np.expand_dims(homo_mesh[0,:], axis=1)\n",
    "    y_coords = np.expand_dims(homo_mesh[1,:], axis=1)\n",
    "    dhoW_dhoP1 = np.dstack((x_coords, np.zeros((x_coords.shape)), y_coords, np.zeros((x_coords.shape)), np.ones((x_coords.shape)), np.zeros((x_coords.shape))))\n",
    "    # print(dhoW_dhoP1.shape)\n",
    "    dhoW_dhoP2 = np.dstack((np.zeros((x_coords.shape)), x_coords, np.zeros((x_coords.shape)),  y_coords, np.zeros((x_coords.shape)), np.ones((x_coords.shape))))\n",
    "    dhoW_dhoP = np.hstack((dhoW_dhoP1, dhoW_dhoP2))\n",
    "\n",
    "    D = np.matmul(grad, dhoW_dhoP)\n",
    "    D = D[:,0,:]\n",
    "\n",
    "    Hess = np.matmul(D.transpose(), D)\n",
    "    Mat = np.matmul(np.linalg.inv(Hess), D.transpose())\n",
    "    \n",
    "    curr_itr = 0\n",
    "    # while np.linalg.norm(del_p) < threshold and curr_itr < maxIters:\n",
    "    while curr_itr < maxIters:\n",
    "      W = np.array([[1,0,0],[0,1,0]])+np.array([[p[0], p[2], p[4]], [p[1], p[3], p[5]]])\n",
    "      homo = np.array([0,0,1])\n",
    "      W = np.vstack((W, homo))\n",
    "      warped_block = np.matmul(W, homo_mesh)\n",
    "      wrapped_img_t1_spline = img_t1_spline.ev(warped_block[1,:], warped_block[0,:])\n",
    "\n",
    "      error = -wrapped_img_t_spline + wrapped_img_t1_spline\n",
    "      error = np.expand_dims(error, axis=1)\n",
    "      # print(error.shape)\n",
    "      # del_p = np.matmul(Mat, error).reshape((-1,))\n",
    "      del_p = (np.matmul(Mat, error)).flatten()\n",
    "      # print(del_p.shape)\n",
    "\n",
    "      inv_warp = np.array([-del_p[0]-(del_p[0]*del_p[3])+(del_p[1]*del_p[2]), -del_p[1], -del_p[2], -del_p[3]-(del_p[0]*del_p[3])+(del_p[1]*del_p[2]),  -del_p[4]-(del_p[3]*del_p[4])+(del_p[2]*del_p[5]), -del_p[5]-(del_p[0]*del_p[5])+(del_p[1]*del_p[4])])\n",
    "      inv_warp = inv_warp/((1+del_p[0])*(1+del_p[3]) - (del_p[1]*del_p[2]))\n",
    "      Warp_inv = np.array([[1,0,0],[0,1,0],[0,0,1]]) + np.concatenate((inv_warp.reshape(3,2).T, np.zeros((1,3))), axis=0)\n",
    "      W_fin = np.matmul(W, Warp_inv)\n",
    "\n",
    "      p[0] = W_fin[0,0] - 1\n",
    "      p[1] = W_fin[1,0]\n",
    "      p[2] = W_fin[0,1]\n",
    "      p[3] = W_fin[1,1] - 1\n",
    "      p[4] = W_fin[0,2]\n",
    "      p[5] = W_fin[1,2]\n",
    "\n",
    "      if np.linalg.norm(del_p) < threshold:\n",
    "        break\n",
    "      curr_itr += 1\n",
    "    M = np.array([[1 + p[0], p[2], p[4]], [p[1], 1 + p[3], p[5]]])\n",
    "    # raise NotImplementedError()\n",
    "    \n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e48ed28e94321846ae54b7f1a476c9ed",
     "grade": false,
     "grade_id": "cell-9d505035dba56569",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q2.2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d25dbd47af9fb1c8dbcad4cf6d85162",
     "grade": true,
     "grade_id": "cell-95b51fa815c97b32",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE <br/>\n",
    "\n",
    "As far as the compuutation speed is concerned, the Matthew-Baker Tracker is much better than either of the Lucas-Kanade (transaltion only, affine) algorithms. This is because in Matthew-Baker we are not calculating the the Hessian and Jacobian at every iteration. However, the accuracy in this case is compromised to a certain extent becuase the errors start to increase when the bounding boxes go out of the dimension and we are supposed to extrapolate the image. <br/>\n",
    "\n",
    "Now, in case of translation only Lucas-Kanade (LK) algorithm, we could see that the performance was best as compared to the other two (affine LK, and Matthew-Baker). I think this is because the videos that we are considering here are mostly representing translation of the objects of interest. So, not considering the affine transformations eliminates any errors that could assimilate due to those parameters and not considering them is fine becuase of the kinds of videos we are using. However, in case of landing when the object of interest was moving closer/farther from the camera, the size of the object kept changing and the tanslation only LK could not take into factor that change in size. Although it could still track the patch in general. <br/>\n",
    "\n",
    "For the affine LK, we can take into factor the changes in the sizes of the object of interest! However, when there is a sudden movement/change, the bounding boxe blows up. We can see this in the ballet video example. When the dancer moves her head suddenly, the bounding box expands suddenly. This happens because while doing gradient descent the slope(direction) of the gradient approaches zero or infinity. And hence the solver is not able to solve for such a jacobian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c18a0c2544adf1bd7ed3fda74dd08b83",
     "grade": false,
     "grade_id": "cell-9d505035dba56570",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b0b69af0161b2d4f3c5c5254a9e52d9",
     "grade": true,
     "grade_id": "cell-95b51fa815c97b33",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 (Extra Credit) Short notes on important optical flow papers (15 points)\n",
    "\n",
    "In this section we will go over three important optical flow papers and summarize them. For each paper, please follow these guidelines: \n",
    "- Please read the papers in detail, focussing on the method described in the paper. \n",
    "- For each paper, write 5 itemized points (6 max, 4 min) describing the method the authors use to solve the problem. \n",
    "- Each point should have *no more* than *2 medium length sentences* and *a math equation*. You will **lose points for verbose descriptions**.\n",
    "- By reading your summary, a person who is motivated about the optic flow problem and has the background on what optic flow is, should understand how the authors posed and solved the problem.\n",
    "- You may add one point (not exceeding max 6 points) to mention something interesting about the results of the paper. E.g. how well does it generalize, how much real world data it needs etc.  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Paper 1: GOTURN  (5 Pts)\n",
    "**[Learning to Track at 100 FPS with Deep Regression Networks. Held, Savarese and Thrun. ECCV'16](https://davheld.github.io/GOTURN/GOTURN.html)** \n",
    "\n",
    "Additional material: [A PyTorch implementation](https://github.com/nrupatunga/goturn-pytorch)\n",
    "\n",
    "Answer:\n",
    "- From frame t-1, crop an image centered at c=(c_x, c_y), with height=k_1h, width=k_1w, where k1 determines context we want to be part of the target object to be tracked.\n",
    "- From frame t, crop an image centered at c=(c_x, x_y), with height=k2h, width=k_2w, where k2 is usually 2, denoting the search space for the current time step. \n",
    "- Pass these two images through two conv nets converting into two embeddings. \n",
    "- Pass this embedding through an FCNN which predicts the center, width, and height of the bounding box for current frame. \n",
    "- Interestingly, the model learns a generic relationship between object motion and appearance and can be used to track novel objects that do not appear in the training set. \n",
    "- However, the model finds difficulty in dealing with occlusions and needs tuning for high speed moving objects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper 2: RAFT  (5 Pts)\n",
    "**[RAFT: Recurrent All-Pairs Field Transforms for Optical Flow. Teed and Deng ECCV'20](https://github.com/princeton-vl/RAFT)** \n",
    "\n",
    "Additional material: [Implementation](https://github.com/princeton-vl/RAFT), [Talk (unofficial)](https://www.youtube.com/watch?v=r3ZtW30exoo)\n",
    "\n",
    "Answer:\n",
    "- Pass a given a pair of consecutive RGB images I_1, I_2 through feature extractor g_\\theta, such that resolution decreases 8 folds, and channels increases to D=256 (choosen by authors).\n",
    "- Additional, pass I_1 through context network h_\\theta to get additional features.\n",
    "- Form correlation volume between image pairs by taking a dot product between feature output by g_\\theta.\n",
    "- Form a correlation pyramid by polling the last two dimensions by kernel sizes (1, 2, 4, 8)\n",
    "- Using an LSTM + conv filters predict f_{k+1} = f_{k+1} + \\Delta f, where \\Delta f is predicted from the correlation volume, hidden state, and f_{k+1}. Initialize f_{k+1} to zero.\n",
    "- For upscaling, take a convex combination of a 3x3 grid of coarse resolution neighbors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paper 3: GM Flow (5 Pts)\n",
    "**[GMFlow: Learning Optical Flow via Global Matching. Xu et al. CVPR'22](https://arxiv.org/pdf/2111.13680.pdf)**\n",
    "\n",
    "Additional material: [Implementation](https://github.com/haofeixu/gmflow)\n",
    "\n",
    "Answer:\n",
    "- This method might produce unreliable results in occluded regions.\n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "- \n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Talk by Utsav Prabhu\n",
    "1. Even though the concept of \"fairness\" is not new, but still it is a big and unsolved problem. Infact this field had seen a rapid explosion recently (2017).\n",
    "2. People sometimes consider accuracy and fairness as mutually exclusive. However research has shown that we can both together! We can have high accuracy of a model along with considering the fairness of the model.\n",
    "3. One of the major reasons for a bias being developed in a model, is due to the dataset it is being trained upon, since the datasets are biased themselves!!\n",
    "4. Fairness is largely classified into \"Equal treatement\" and \"Equal outcomes\" of the models. These are further broken down into \"Group fairness\", \"Individual Fairness\" under \"Equal outcome\"; and \"Counterfactual Fairness\", \"Interventional Fairness\" under \"Equal treatement\". And currently a majority of research is being conducted in the field of Group fairness.\n",
    "5. In the last part of the lecture Utsav touched upon how we can solve this issue using learning, and some tools that can be used for datasets compositional statics. He mentioned that although people have made some progress in solving this problem but still there are more unknown unknowns! And adversarial testing can reveal previously unknown failure modes and undesired system behaviors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FiftyOne\n",
    "This is just one single screenshot but there are >5 images that are incorrectly labled in this one screenshot itself. Like, <br/>\n",
    "1. Ship - Frog\n",
    "2. Airplane - Ship\n",
    "3. Ship - Deer\n",
    "4. Truck - Cat\n",
    "5. Dog - Cat\n",
    "![](FiftyOne.jpeg) <br />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
